peaks {
  server {
    environment = "debug"
    server-instances = 1
    root-url = "http://localhost"
    http-port = 4000
    jwt-secret = "jwt"
    session-timeout = 1 day
    work-registration-timeout = 30 seconds
    web-integration = true
    ask-timeout = 20 seconds
    ask-timeout-filesystem = 60 seconds
    snapshot-interval = 500
    auto-keyspace-generation = false
    min-task-threads = 8
    max-task-threads = 64
    task-threads-increment = 8
    task-submission-interval = 3 seconds
    resource-override {
      dia-db-search-threads = 32
    }

    data-loader {
      load-interval = 2 seconds
      parallelism = 2
      timeout = 2 hours
      threads-per-loader = 2
      retry-in-seconds = [30, 60, 120]
      timstof-reader = "jni" # another option is stream
      memory = 2 #in gbs
    }

    data-upload {
        queue-timeout = 12 hours
        pending-timeout = 1 minute
    }

    archiver {
      minions = 1
      task-parallelism = 2
      auto-recovery = true
      snapshot-interval = 500
    }

    fasta-database.timeout = 8 hours

    api {
        root = "/apis"
        allow-cors = true
        search-limit = 20
    }

    uploader.extra-quota = 1

    peptide-database {
      folder = "peptide-database"
      filename-taxonomy-regex = ".+(\\d+)"
    }

    spectral-library {
      creation-workers = 1
    }

    cluster {
      name = "PeaksCluster"
      is-master = true
      master {
        cleanup-interval = 30 seconds
        work-timeout = 3 minutes
        number-of-retries-per-task = 3
        parallelism = 8
        internal-communication-timeout = 500 ms
      }
      worker {
        cleanup-interval = 20 seconds # the time worker does a cleanup
        result-ack-interval = 5 seconds # if no response from master after this interval, will try to reconnect
        check-version = true # Only workers with same version as master will be allowed to register.
      }
    }

    ssl {
      certificate-location = ""
      certificate-password = ""
    }

    email {
      domain-name = ""
    }
  }

  cassandra-monitor {
    is-cassandra-monitor = false
    node-ip-address = "127.0.0.1"
    drives = "C"
    update-interval = 300
    node-communication-timeout = 1200
  }

  instrument-daemon {
    is-instrument-daemon = false
    scanning-directory = "C"
    name = ""
    instrument-type = ""
    update-interval = 3
    node-communication-timeout = 1200
    api-key = ""
    ip-address = ""
    master-url = "http://localhost"
    master-http-port = 4000
    file-size-min-in-mb = 10
    scanning-depth = 2
  }

  worker {
    #max resource we can allocate
    max-cpu = 4
    gpus = []
    max-memory = 10 #in GB
    #default resource we allocate per task
    default-cpu = 4
    default-gpu = 0
    default-memory = 10 #in GB
    detached = false # detached mode create service in sub process
    task-timeout = 12 hours
    message-timeout = 3 seconds
    heartbeat-timeout = 20 minutes
    debug {
      enabled = false
      services {
        all = []
        # denovoService = [{delay = 1 hour}, {throw = true}, {delay = 10 seconds}]
      }
    }
  }
}
